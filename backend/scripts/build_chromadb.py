import os
import json
import shutil
import logging
from datetime import datetime
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain_huggingface import HuggingFaceEmbeddings
from dotenv import load_dotenv
import torch
import time
from tqdm import tqdm
import chromadb

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (backend í´ë” ê¸°ì¤€)
load_dotenv("../.env")

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # ë¡œê·¸ íŒŒì¼ëª… (í˜„ì¬ ì‹œê°„ í¬í•¨)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f"build_chromadb_{timestamp}.log"
    log_filepath = os.path.join(log_dir, log_filename)
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger('build_chromadb')
    logger.setLevel(logging.INFO)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ìƒì„¸ ë¡œê·¸)
    file_handler = logging.FileHandler(log_filepath, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(file_formatter)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ (ê°„ë‹¨í•œ ë¡œê·¸)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(message)s')
    console_handler.setFormatter(console_formatter)
    
    # í•¸ë“¤ëŸ¬ ì¶”ê°€
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger, log_filepath

# ë¡œê±° ì´ˆê¸°í™”
logger, log_filepath = setup_logging()

logger.info("=" * 60)
logger.info("ChromaDB ë¹Œë“œ ì‹œì‘")
logger.info(f"ë¡œê·¸ íŒŒì¼: {log_filepath}")
logger.info("=" * 60)

# ì„¤ì •
JSON_DIR = "../datas/json_results"
CHROMA_DIR = "../datas/chroma_db"        # ì €ì¥í•  Chroma DB ê²½ë¡œ

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL", "intfloat/multilingual-e5-large")

# ë””ë°”ì´ìŠ¤ ì„¤ì • - ë”°ì˜´í‘œ ì œê±° ë° ê²€ì¦
device_env = os.getenv("EMBEDDING_DEVICE", "")
logger.info(f"í™˜ê²½ ë³€ìˆ˜ EMBEDDING_DEVICE: '{device_env}'")

if device_env:
    EMBEDDING_DEVICE = device_env.strip().strip("'\"")  # ë”°ì˜´í‘œ ì œê±°
    logger.info(f"ë”°ì˜´í‘œ ì œê±° í›„: '{EMBEDDING_DEVICE}'")
else:
    EMBEDDING_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"ê¸°ë³¸ê°’ ì„¤ì •: '{EMBEDDING_DEVICE}'")

EMBEDDING_BATCH_SIZE = int(os.getenv("EMBEDDING_BATCH_SIZE", "32"))

logger.info(f"ì„ë² ë”© ëª¨ë¸ ì„¤ì •:")
logger.info(f"   - ëª¨ë¸: {EMBEDDING_MODEL_NAME}")
logger.info(f"   - ë””ë°”ì´ìŠ¤: {EMBEDDING_DEVICE}")
logger.info(f"   - ë°°ì¹˜ í¬ê¸°: {EMBEDDING_BATCH_SIZE}")

# CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
if not torch.cuda.is_available():
    logger.error("âŒ CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
    logger.error("GPU ë“œë¼ì´ë²„ì™€ PyTorch CUDA ë²„ì „ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    logger.error("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit(1)

logger.info(f"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")

# JSON í´ë” í™•ì¸
if not os.path.exists(JSON_DIR):
    logger.error(f"ì˜¤ë¥˜: JSON í´ë” '{JSON_DIR}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    logger.error("ë¨¼ì € JSON ë³€í™˜ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
    exit()

# ê¸°ì¡´ Chroma DB ë””ë ‰í† ë¦¬ê°€ ìˆë‹¤ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ì‹œì‘
if os.path.exists(CHROMA_DIR):
    logger.warning(f"âš ï¸ ê¸°ì¡´ Chroma DB ë””ë ‰í† ë¦¬ '{CHROMA_DIR}'ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤. (ì¤‘ë³µ ë°©ì§€)")
    shutil.rmtree(CHROMA_DIR) # í´ë”ì™€ ê·¸ ì•ˆì˜ ëª¨ë“  ë‚´ìš©ì„ ì‚­ì œ

# ì„ë² ë”© ë¡œë”© (CUDA í•„ìˆ˜)
try:
    embedding_model = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={'device': EMBEDDING_DEVICE},
        encode_kwargs={'batch_size': EMBEDDING_BATCH_SIZE}
    )
    logger.info(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {EMBEDDING_DEVICE}")
except RuntimeError as e:
    logger.error(f"âŒ CUDA ë””ë°”ì´ìŠ¤ ì˜¤ë¥˜ ë°œìƒ: {e}")
    logger.error("CUDAê°€ í•„ìš”í•©ë‹ˆë‹¤. GPU ë“œë¼ì´ë²„ì™€ PyTorch CUDA ë²„ì „ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    logger.error("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit(1)

# Document ëª©ë¡ ìƒì„±
all_documents = []
logger.info(f"\nï¿½ï¿½ JSON íŒŒì¼ ë¡œë”© ì¤‘...")

# nttSn ìˆœì„œë¡œ ì •ë ¬í•˜ì—¬ ë¡œë“œ
json_files = []
for filename in os.listdir(JSON_DIR):
    if filename.endswith(".json"):
        try:
            # íŒŒì¼ëª…ì—ì„œ nttSn ì¶”ì¶œ (ì˜ˆ: "13176_union.json" â†’ 13176)
            nttsn = int(filename.split('_')[0])
            json_files.append((nttsn, filename))
        except (ValueError, IndexError) as e:
            logger.info(f"âš ï¸ íŒŒì¼ëª… íŒŒì‹± ì˜¤ë¥˜: {filename} - {e}")
            continue

# nttSn ìˆœì„œë¡œ ì •ë ¬
json_files.sort(key=lambda x: x[0])

logger.info(f"ì´ {len(json_files)}ê°œì˜ JSON íŒŒì¼ì„ nttSn ìˆœì„œë¡œ ë¡œë“œí•©ë‹ˆë‹¤...")

# ì •ë ¬ëœ ìˆœì„œë¡œ ë¡œë“œ
for nttsn, filename in json_files:
    file_path = os.path.join(JSON_DIR, filename)
    with open(file_path, "r", encoding="utf-8") as f:
        try:
            data = json.load(f)
            for item in data:
                # metadataë¥¼ ChromaDBê°€ í—ˆìš©í•˜ëŠ” í˜•íƒœë¡œ í‰ë©´í™”
                original_metadata = item["metadata"]
                flattened_metadata = {}
                
                # metadata ê²€ì¦: ë”•ì…”ë„ˆë¦¬ ê°’ì´ ìˆëŠ”ì§€ í™•ì¸
                has_dict_value = False
                for key, value in original_metadata.items():
                    if isinstance(value, dict):
                        has_dict_value = True
                        logger.info(f"âš ï¸ ë”•ì…”ë„ˆë¦¬ ê°’ ë°œê²¬: {filename} - {key}: {value}")
                        break
                
                if has_dict_value:
                    logger.info(f"âŒ ê±´ë„ˆë›°ê¸°: {filename} - ë”•ì…”ë„ˆë¦¬ ê°’ì´ í¬í•¨ëœ metadata")
                    continue
                
                # ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ í‰ë©´í™”
                for key, value in original_metadata.items():
                    if isinstance(value, dict):
                        # ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ì˜ ê° í‚¤-ê°’ì„ í‰ë©´í™”
                        for sub_key, sub_value in value.items():
                            flattened_metadata[f"{key}_{sub_key}"] = sub_value
                    else:
                        # ë‹¨ìˆœí•œ ê°’ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        flattened_metadata[key] = value
                
                doc = Document(
                    page_content=item["text"],
                    metadata=flattened_metadata
                )
                all_documents.append(doc)
            logger.info(f"âœ… ë¡œë“œ ì™„ë£Œ: {filename} (nttSn: {nttsn}, {len(data)}ê°œ í•­ëª©)")
        except Exception as e:
            logger.info(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {filename} - {e}")

logger.info(f"\nğŸ” ì´ {len(all_documents)}ê°œì˜ ë¬¸ì„œë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤...")

def create_chroma_with_progress(documents, embedding_model, persist_directory):
    """
    ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ ë°°ì¹˜ë¡œ ì„ë² ë”©í•˜ê³  ChromaDBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (ìµœì‹  ë°©ì‹)
    """
    # 1. ChromaDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    client = chromadb.PersistentClient(path=persist_directory)
    collection_name = "my_report_collection" # ì»¬ë ‰ì…˜ ì´ë¦„ ì§€ì •

    # ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆë‹¤ë©´ ì‚­ì œ
    if collection_name in [c.name for c in client.list_collections()]:
        client.delete_collection(name=collection_name)
    
    # 2. ì„ë² ë”© í•¨ìˆ˜ ì—†ì´ ì»¬ë ‰ì…˜ ìƒì„±
    collection = client.create_collection(name=collection_name)

    # 3. ë¬¸ì„œë“¤ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
    batch_size = EMBEDDING_BATCH_SIZE # í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì„œ ìˆ˜, ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ
    
    logger.info(f"ì´ {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ {batch_size}ê°œì”© ë‚˜ëˆ„ì–´ ì„ë² ë”© ë° ì €ì¥í•©ë‹ˆë‹¤...")

    for i in tqdm(range(0, len(documents), batch_size), desc="ChromaDBì— ì €ì¥ ì¤‘"):
        batch_docs = documents[i:i+batch_size]
        
        # ë¬¸ì„œ ë‚´ìš©ë§Œ ì¶”ì¶œí•˜ì—¬ ì„ë² ë”©
        batch_contents = [doc.page_content for doc in batch_docs]
        embeddings = embedding_model.embed_documents(batch_contents)
        
        # ë©”íƒ€ë°ì´í„°ì™€ ID ì¤€ë¹„
        metadatas = [doc.metadata for doc in batch_docs]
        ids = [f"id_{i+j}" for j in range(len(batch_docs))] # ê³ ìœ  ID ìƒì„±
        
        # 4. ì»¬ë ‰ì…˜ì— ë°ì´í„° ì¶”ê°€
        collection.add(
            ids=ids,
            embeddings=embeddings,
            metadatas=metadatas,
            documents=batch_contents # ì›ë³¸ í…ìŠ¤íŠ¸ë„ í•¨ê»˜ ì €ì¥
        )

    logger.info("âœ… ëª¨ë“  ë¬¸ì„œì˜ ì„ë² ë”© ë° ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    return collection

# ìŠ¤í¬ë¦½íŠ¸ì˜ ë©”ì¸ ë¶€ë¶„ì—ì„œ ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
create_chroma_with_progress(all_documents, embedding_model, CHROMA_DIR) 