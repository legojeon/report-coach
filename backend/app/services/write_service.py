import os
import sys
from typing import List, Dict, Any, Optional, Tuple
from fastapi import HTTPException
from .search_service import SearchService
from .analysis_service import AnalysisService
from .logger_service import LoggerService
from google import genai
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
import traceback
import uuid

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

API_KEY = os.getenv("GOOGLE_API_KEY")
if not API_KEY:
    raise ValueError("GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
client = genai.Client(api_key=API_KEY)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
try:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    prompt_path = os.path.join(current_dir, "..", "..", "prompts", "prompt_write.txt")
    with open(prompt_path, "r", encoding="utf-8") as f:
        PROMPT_TEMPLATE = f.read()
except FileNotFoundError:
    raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")

PROMPT = PromptTemplate.from_template(PROMPT_TEMPLATE)

# Write ì±„íŒ… ížˆìŠ¤í† ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
write_chat_histories = {}  # key: user_id, value: List[Dict] (ì±„íŒ… ížˆìŠ¤í† ë¦¬)
write_user_reports = {}  # key: user_id, value: user_report ë‚´ìš©

def get_write_history_key(user_id: str) -> str:
    """ì‚¬ìš©ìžë³„ Write ì±„íŒ… ížˆìŠ¤í† ë¦¬ í‚¤ ìƒì„±"""
    return f"write_{user_id}"

def cleanup_write_history(user_id: str):
    """Write ížˆìŠ¤í† ë¦¬ ì •ë¦¬"""
    history_key = get_write_history_key(user_id)
    if history_key in write_chat_histories:
        del write_chat_histories[history_key]
        print(f"[WRITE_CLEANUP] Write ì±„íŒ… ížˆìŠ¤í† ë¦¬ ì‚­ì œë¨: {history_key}")
    
    if user_id in write_user_reports:
        del write_user_reports[user_id]
        print(f"[WRITE_CLEANUP] Write ì‚¬ìš©ìž ë³´ê³ ì„œ ì •ë³´ ì‚­ì œë¨: {user_id}")


class WriteService:
    """WritePage ì±„íŒ… ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    @staticmethod
    async def analyze_for_write(
        user_query: str,
        user_report: str,
        report_numbers: List[str],
        user_id: str,
        logger_service: Optional[LoggerService] = None,
        auth_token: Optional[str] = None
    ) -> Tuple[str, dict]:
        """ì‚¬ìš©ìž ë³´ê³ ì„œ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë¶„ì„ ë° ë‹µë³€ ìƒì„±"""
        generation_config = {
            "max_output_tokens": int(os.getenv("GEMINI_MAX_TOKENS", "2048")),
            "temperature": float(os.getenv("GEMINI_TEMPERATURE", "0.1")),
            "top_p": float(os.getenv("GEMINI_TOP_P", "0.9")),
            "top_k": int(os.getenv("GEMINI_TOP_K", "40"))
        }

        gemini_model_name = os.getenv("GEMINI_MODEL", "gemini-1.5-flash-latest")
        # model = genai.GenerativeModel(model_name=gemini_model_name, generation_config=generation_config)

        # ê° ë³´ê³ ì„œ ë‚´ìš©ì„ ì½ì–´ì„œ ê²°í•©
        reports_content = ""
        for i, number in enumerate(report_numbers, 1):
            current_dir = os.path.dirname(os.path.abspath(__file__))
            union_file_path = os.path.join(current_dir, "..", "..", "datas", "extracted_pdf", "union", f"{number}_union.txt")

            if os.path.exists(union_file_path):
                try:
                    with open(union_file_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                    if content:
                        reports_content += f"\n=== ë³´ê³ ì„œ {number} ===\n{content}\n"
                except Exception as e:
                    print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ (ë³´ê³ ì„œ {number}): {e}")

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë³€ìˆ˜ ëŒ€ìž…
        prompt = PROMPT_TEMPLATE.format(
            user_query=user_query,
            user_report=user_report,
            reports_content=reports_content
        )

        try:
            response = client.models.generate_content(
                model=gemini_model_name,
                contents=prompt,
            )
            
            # ì‚¬ìš©ëŸ‰ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            usage_metadata = {}
            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                usage_metadata = {
                    'total_token_count': response.usage_metadata.total_token_count,
                    'prompt_token_count': response.usage_metadata.prompt_token_count,
                    'candidates_token_count': response.usage_metadata.candidates_token_count
                }

            if logger_service and usage_metadata:
                try:
                    await logger_service.log_ai_usage(
                        user_id=user_id,
                        service_name="write_chat",
                        request_prompt=user_query,
                        request_token_count=usage_metadata.get('prompt_token_count', 0),
                        response_token_count=usage_metadata.get('candidates_token_count', 0),
                        total_token_count=usage_metadata.get('total_token_count', 0),
                        auth_token=auth_token  # í† í° ì „ë‹¬
                    )
                except Exception as log_error:
                    print(f"âŒ ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {log_error}")
            
            return response.text, usage_metadata
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}", {}
    
    @staticmethod
    async def chat_with_write(
        query: str, 
        user_id: str, 
        user_report: str = "",
        history: Optional[List[Dict[str, Any]]] = None,
        logger_service: Optional[LoggerService] = None,
        auth_token: Optional[str] = None
    ) -> Tuple[str, Dict[str, Any]]:
        """analyze_for_write()ë¥¼ í™œìš©í•œ ì±„íŒ… ë©”ì‹œì§€ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        try:
            print(f"âœï¸ Write ì±„íŒ… ìš”ì²­: {query}")
            print(f"âœï¸ user_id: {user_id}")
            print(f"âœï¸ history: {history}")
            
            # ížˆìŠ¤í† ë¦¬ í‚¤ ìƒì„±
            history_key = get_write_history_key(user_id)
            print(f"âœï¸ history_key: {history_key}")
            
            # 1. ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ë³´ê³ ì„œ ì°¾ê¸°
            search_result = await SearchService.search_documents(
                query=query,
                k=5,  # ìƒìœ„ 5ê°œ ë³´ê³ ì„œ ì‚¬ìš©
                user_id=user_id,
                logger_service=logger_service,
                is_hidden=True,  # write_chatì—ì„œ í˜¸ì¶œí•˜ëŠ” ê²€ìƒ‰ì€ ìˆ¨ê¹€ ì²˜ë¦¬
                auth_token=auth_token  # í† í° ì „ë‹¬
            )
            
            if not search_result.get('results'):
                return "ê´€ë ¨ëœ ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”.", {}
            
            # 2. ê²€ìƒ‰ëœ ë³´ê³ ì„œ ë²ˆí˜¸ë“¤ ì¶”ì¶œ
            report_numbers = [str(result['number']) for result in search_result['results']]
            print(f"ðŸ“Š ê´€ë ¨ ë³´ê³ ì„œ: {report_numbers}")
            
            # 3. analyze_for_write()ë¥¼ í†µí•´ ë‹µë³€ ìƒì„±
            analysis_result, usage_metadata = await WriteService.analyze_for_write(
                user_query=query,
                user_report=user_report,
                report_numbers=report_numbers,
                user_id=user_id,
                logger_service=logger_service,
                auth_token=auth_token  # í† í° ì „ë‹¬
            )
            
            # 4. ížˆìŠ¤í† ë¦¬ ê´€ë¦¬
            if history_key not in write_chat_histories:
                write_chat_histories[history_key] = []
            
            # ì‚¬ìš©ìž ë©”ì‹œì§€ì™€ AI ì‘ë‹µì„ ížˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            write_chat_histories[history_key].append({
                "role": "user",
                "content": query,
                "timestamp": str(uuid.uuid4())
            })
            
            write_chat_histories[history_key].append({
                "role": "assistant",
                "content": analysis_result,
                "timestamp": str(uuid.uuid4())
            })
            
            # ì‚¬ìš©ìž ë³´ê³ ì„œ ì •ë³´ ì €ìž¥
            write_user_reports[user_id] = user_report
            
            print(f"âœï¸ ížˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€ë¨. ì´ {len(write_chat_histories[history_key])}ê°œ ë©”ì‹œì§€")
            
            # 5. ì‚¬ìš©ëŸ‰ ë©”íƒ€ë°ì´í„°ì— ê²€ìƒ‰ ê²°ê³¼ ì •ë³´ ì¶”ê°€
            if usage_metadata:
                usage_metadata['search_results'] = search_result.get('results', [])
                usage_metadata['report_numbers'] = report_numbers
            
            print(f"âœ… Write ì±„íŒ… ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            return analysis_result, usage_metadata
            
        except Exception as e:
            print(f"âŒ Write ì±„íŒ… ì¤‘ ì˜¤ë¥˜: {e}")
            print(f"âŒ ì „ì²´ ì—ëŸ¬ ì •ë³´:")
            print(traceback.format_exc())
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", {}
    
    @staticmethod
    async def get_write_chat_history(user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ìžì˜ Write ì±„íŒ… ížˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        history_key = get_write_history_key(user_id)
        if history_key in write_chat_histories:
            return {
                'session_id': history_key,
                'has_session': True,
                'history': write_chat_histories[history_key],
                'report_numbers': [],  # í˜„ìž¬ëŠ” ë¹ˆ ë°°ì—´, í•„ìš”ì‹œ êµ¬í˜„
                'user_report': write_user_reports.get(user_id, "")
            }
        return {
            'session_id': history_key,
            'has_session': False,
            'history': [],
            'report_numbers': [],
            'user_report': ""
        }
    
    @staticmethod
    async def cleanup_write_session(user_id: str) -> bool:
        """ì‚¬ìš©ìžì˜ Write ì±„íŒ… ížˆìŠ¤í† ë¦¬ ì •ë¦¬"""
        try:
            cleanup_write_history(user_id)
            return True
        except Exception as e:
            print(f"âŒ Write ížˆìŠ¤í† ë¦¬ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    @staticmethod
    async def save_chat_message(
        user_id: str, 
        message: str, 
        response: str, 
        report_numbers: List[str]
    ) -> bool:
        """ì±„íŒ… ë©”ì‹œì§€ ì €ìž¥ (í–¥í›„ êµ¬í˜„)"""
        # í˜„ìž¬ëŠ” True ë°˜í™˜, í•„ìš”ì‹œ DB ì €ìž¥ êµ¬í˜„
        return True 