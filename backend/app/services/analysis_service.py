import os
import sys
from google import genai
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from typing import List, Optional, Tuple
from .logger_service import LoggerService

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

API_KEY = os.getenv("GOOGLE_API_KEY")
if not API_KEY:
    raise ValueError("GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
client = genai.Client(api_key=API_KEY)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
try:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    prompt_path = os.path.join(current_dir, "..", "..", "prompts", "prompt_refine.txt")
    with open(prompt_path, "r", encoding="utf-8") as f:
        PROMPT_TEMPLATE = f.read()
except FileNotFoundError:
    raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")

PROMPT = PromptTemplate.from_template(PROMPT_TEMPLATE)


class AnalysisService:
    """ë¶„ì„ ê´€ë ¨ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    @staticmethod
    async def generate_combined_answer(contents: List[str], report_numbers: List[str], user_query: str, user_id: str, logger_service: Optional[LoggerService] = None, auth_token: Optional[str] = None) -> Tuple[str, dict]:
        """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ë³´ê³ ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í†µí•© ë‹µë³€ ìƒì„±"""
        generation_config = {
            "max_output_tokens": int(os.getenv("GEMINI_MAX_TOKENS", "2048")),
            "temperature": float(os.getenv("GEMINI_TEMPERATURE", "0.1")),
            "top_p": float(os.getenv("GEMINI_TOP_P", "0.9")),
            "top_k": int(os.getenv("GEMINI_TOP_K", "40"))
        }

        gemini_model_name = os.getenv("GEMINI_MODEL", "gemini-1.5-flash-latest")
        # model = genai.GenerativeModel(model_name=gemini_model_name, generation_config=generation_config)
        # promptëŠ” ì•„ë˜ì—ì„œ ìƒì„±

        # ê° ë³´ê³ ì„œ ë‚´ìš©ì„ êµ¬ì¡°í™”í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        reports_content = ""
        for i, (content, number) in enumerate(zip(contents, report_numbers), 1):
            reports_content += f"\n=== ë³´ê³ ì„œ {number} ===\n{content.strip()}\n"

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë³€ìˆ˜ ëŒ€ì…
        prompt = PROMPT_TEMPLATE.format(
            report_count=len(report_numbers),
            user_query=user_query,
            reports_content=reports_content
        )

        try:
            response = client.models.generate_content(
                model=gemini_model_name,
                contents=prompt,
            )
            
            # ì‚¬ìš©ëŸ‰ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            usage_metadata = {}
            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                usage_metadata = {
                    'total_token_count': response.usage_metadata.total_token_count,
                    'prompt_token_count': response.usage_metadata.prompt_token_count,
                    'candidates_token_count': response.usage_metadata.candidates_token_count
                }

            if logger_service and usage_metadata:
                try:
                    await logger_service.log_ai_usage(
                        user_id=user_id,
                        service_name="analyze_reports",
                        request_prompt=user_query,
                        request_token_count=usage_metadata.get('prompt_token_count', 0),
                        response_token_count=usage_metadata.get('candidates_token_count', 0),
                        total_token_count=usage_metadata.get('total_token_count', 0),
                        auth_token=auth_token  # í† í° ì „ë‹¬
                    )
                except Exception as log_error:
                    print(f"âŒ ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {log_error}")
            return response.text.strip(), usage_metadata
        except Exception as e:
            return f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}", {}

    @staticmethod
    async def analyze_combined_reports(report_numbers: List[str], original_query: str, user_id: Optional[str] = None, logger_service: Optional[LoggerService] = None, auth_token: Optional[str] = None) -> Tuple[str, dict]:
        """ì£¼ì–´ì§„ ë³´ê³ ì„œ ë²ˆí˜¸ë“¤ì˜ union.txt íŒŒì¼ì„ ì½ì–´ì„œ í†µí•© ë¶„ì„ ìˆ˜í–‰"""
        contents = []

        for i, number in enumerate(report_numbers, 1):
            current_dir = os.path.dirname(os.path.abspath(__file__))
            union_file_path = os.path.join(current_dir, "..", "..", "datas", "extracted_pdf", "union", f"{number}_union.txt")

            if not os.path.exists(union_file_path):
                return f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {union_file_path}", {}

            try:
                with open(union_file_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()

                if not content:
                    return f"íŒŒì¼ì´ ë¹„ì–´ìˆìŒ: {union_file_path}", {}

                contents.append(content)

            except Exception as e:
                return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}", {}

        if not contents:
            return "ë¶„ì„í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.", {}

        answer, usage_metadata = await AnalysisService.generate_combined_answer(contents, report_numbers, original_query, user_id, logger_service, auth_token)
        return answer, usage_metadata

    @staticmethod
    async def analyze_reports(query: str, report_numbers: List[str], user_id: Optional[str] = None, logger_service: Optional[LoggerService] = None, auth_token: Optional[str] = None) -> Tuple[str, dict]:
        """ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ - ë³´ê³ ì„œ ë²ˆí˜¸ ì¶œë ¥ í›„ ë¶„ì„ ìˆ˜í–‰"""
        # ë¶„ì„í•  ë³´ê³ ì„œ ë²ˆí˜¸ ì¶œë ¥
        print(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ ë³´ê³ ì„œ: {', '.join(report_numbers)}")
        
        # ë¶„ì„ ìˆ˜í–‰
        result, usage_metadata = await AnalysisService.analyze_combined_reports(report_numbers, query, user_id, logger_service, auth_token)
        return result, usage_metadata

 